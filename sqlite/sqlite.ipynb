{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Saving Scraped Data To SQLite Database With Scrapy Pipelines](https://scrapeops.io/python-scrapy-playbook/scrapy-save-data-sqlite/)\n",
    "\n",
    "# Scrapy PipelineでスクレイピングされたデータをSQLiteに保存する"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "プロジェクトの作成"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "scrapy startproject sqlite_demo\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treeの確認"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "tree\n",
    "\n",
    ".\n",
    "├── scrapy.cfg\n",
    "└── sqlite_demo\n",
    "    ├── __init__.py\n",
    "    ├── items.py\n",
    "    ├── middlewares.py\n",
    "    ├── pipelines.py\n",
    "    ├── settings.py\n",
    "    └── spiders\n",
    "        └── __init__.py\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spiderの作成"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "scrapy genspider quotes quotes.toscrape.com\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# spiders/quotes.py\n",
    "import scrapy\n",
    "from sqlite_demo.sqlite_demo.items import QuoteItem\n",
    "\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    allowed_domains = [\"quotes.toscrape.com\"]\n",
    "    start_urls = [\"https://quotes.toscrape.com\"]\n",
    "\n",
    "    def start_requests(self):\n",
    "        url = \"https://quotes.toscrape.com/\"\n",
    "        yield scrapy.Request(url, callback=self.parse)\n",
    "\n",
    "    def parse(self, response):\n",
    "        quote_item = QuoteItem()\n",
    "        for quote in response.css(\"div.quote\"):\n",
    "            quote_item[\"text\"] = quote.css(\"span.text::text\").get()\n",
    "            quote_item[\"author\"] = quote.css(\"small.author::text\").get()\n",
    "            quote_item[\"tags\"] = quote.css(\"div.tags a.tag::text\").getall()\n",
    "            yield quote_item\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "items.pyの編集"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# items.py\n",
    "from scrapy.item import Item, Field\n",
    "\n",
    "\n",
    "class QuoteItem(Item):\n",
    "    text = Field()\n",
    "    tags = Field()\n",
    "    author = Field()\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SQLite データベースとテーブルの作成\n",
    "\n",
    "- `__init__`メソッドの中で、pipelineがspiderによって起動されるたびに、次のような処理を行うように設定する。\n",
    "  - データベース`demo.db`に接続する。存在しない場合はデータベースを作成する。\n",
    "  - データベースでSQLコマンドを実行するために使用するカーソルを作成する。\n",
    "  - データベースにまだ存在しない場合は、`text`、`tags`、`author`のカラムを持つ新しいテーブル`quotes`を作成する。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# pipeline.py\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "class SqliteDemoPipeline:\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "\n",
    "        # Create/Connect to database\n",
    "        self.con = sqlite3.connect(\"demo.db\")\n",
    "\n",
    "        # Create cursor, used to execute commands\n",
    "        self.cur = self.con.cursor()\n",
    "\n",
    "        # Create quotes table if none exists\n",
    "        self.cur.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS quotes(\n",
    "                text TEXT,\n",
    "                tags TEXT,\n",
    "                author TEXT\n",
    "            )\n",
    "        \"\"\")\n",
    "\n",
    "    def process_item(self, item, spider):\n",
    "        return item\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. スクレイピングしたものをデータベースに保存する\n",
    "\n",
    "- Scrapy pipelineの中の`process_item`イベントを使って、スクレイピングしたデータをSQLiteデータベースに保存する。\n",
    "- `process_item`は、spiderによってitemがスクレイピングされるたびに起動されるので、itemsのデータをデータベースに挿入する`process_item`メソッドを設定する。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# pipeline.py\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "class SqliteDemoPipeline:\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "\n",
    "        # Create/Connect to database\n",
    "        self.con = sqlite3.connect(\"demo.db\")\n",
    "\n",
    "        # Create cursor, used to execute commands\n",
    "        self.cur = self.con.cursor()\n",
    "\n",
    "        # Create quotes table if none exists\n",
    "        self.cur.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS quotes(\n",
    "                text TEXT,\n",
    "                tags TEXT,\n",
    "                author TEXT\n",
    "            )\n",
    "        \"\"\")\n",
    "\n",
    "    def process_item(self, item, spider):\n",
    "\n",
    "        # Define insert statement\n",
    "        self.cur.execute(\"\"\"\n",
    "            INSERT INTO quotes (text, tags, author) VALUES (?, ?, ?)\n",
    "        \"\"\",\n",
    "        (\n",
    "            item[\"text\"],\n",
    "            str(item[\"tags\"]),\n",
    "            item[\"author\"]\n",
    "        )\n",
    "        )\n",
    "\n",
    "        # Execute insert of data into database\n",
    "        self.con.commit()\n",
    "        return item\n",
    "\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SQLのinsert文を定義し、データを与える（注、tagsの値は配列なので文字列化する）。\n",
    "- `self.con.commit()`コマンドを使って、データを挿入する。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Item Pipelineの有効化\n",
    "\n",
    "- Item Pipelineを有効にするために、`settings.py`ファイルにincludeする。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# settings.py\n",
    "ITEM_PIPELINES = {\n",
    "    \"sqlite_demo.pipelines.SqliteDemoPipeline\": 300,\n",
    "}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "スクレイピングの実行"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "scrapy crawl quotes\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 新しいデータのみ保存\n",
    "\n",
    "- itemがすでにデータベースにあるかどうかを確認してから再度挿入するように、pipelineを再構成する。\n",
    "- `pipelines.py`ファイルに`SqliteNoDuplicatesPipeline`という新しいpipelineを作成し、\n",
    "- `process_item`メソッドを変更して、新しいデータのみをデータベースに挿入する。\n",
    "- データベースで`item['text']`を検索し、それがない場合にのみ新しい項目を挿入する。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# pipelines.py\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "class SqliteNoDuplicatesPipeline:\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "\n",
    "        # Create/Connect to database\n",
    "        self.con = sqlite3.connect(\"demo.db\")\n",
    "\n",
    "        # Create cursor, used to execute commands\n",
    "        self.cur = self.con.cursor()\n",
    "\n",
    "        # Create quotes table if none exists\n",
    "        self.cur.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS quotes(\n",
    "                text TEXT,\n",
    "                tags TEXT,\n",
    "                author TEXT\n",
    "            )\n",
    "        \"\"\")\n",
    "\n",
    "    def process_item(self, item, spider):\n",
    "\n",
    "        # Check to see if text is already in database\n",
    "        self.cur.execute(\n",
    "            \"select * from quotes where text = ?\",\n",
    "            (item[\"text\"],)\n",
    "        )\n",
    "        result = self.cur.fetchone()\n",
    "\n",
    "        # If it is in DB, create log message\n",
    "        if result:\n",
    "            spider.logger.warn(\n",
    "                \"Item already in database: %s\" % item[\"text\"]\n",
    "            )\n",
    "        # If text isn't in the DB, insert date\n",
    "        else:\n",
    "            # Define insert statement\n",
    "            self.cur.execute(\n",
    "                \"\"\"INSERT INTO quotes (text, tags, author) VALUES (?, ?, ?)\"\"\",\n",
    "                (\n",
    "                    item[\"text\"],\n",
    "                    str(item[\"tags\"]),\n",
    "                    item[\"author\"]\n",
    "                )\n",
    "            )\n",
    "            # Execute insert of data into database\n",
    "            self.con.commit()\n",
    "\n",
    "        return item\n",
    "````"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- このパイプラインを有効にするには、\n",
    "  - `settings.py`を更新して、以前の`SqliteDemoPipeline`パイプラインではなく、`SqliteNoDuplicatesPipeline`を使用するようにする。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# settings.py\n",
    "ITEM_PIPELINES = {\n",
    "    # \"sqlite_demo.pipelines.SqliteDemoPipeline\": 300,\n",
    "    \"sqlite_demo.pipelines.SqliteNoDuplicatesPipeline\": 300,\n",
    "}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで、quotes spiderを実行すると、pipelineはデータベースにまだない新しいデータだけを保存するようになる。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
