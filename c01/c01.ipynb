{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Scrapy Beginners Series Part 1: How To Build Your First Production Scraper](https://scrapeops.io/python-scrapy-playbook/scrapy-beginners-guide/)\n",
    "\n",
    "# Scrapy åˆå¿ƒè€…å‘ã‘ã‚·ãƒªãƒ¼ã‚º ãƒ‘ãƒ¼ãƒˆ 1: åˆã‚ã¦ã®ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ ã‚¹ã‚¯ãƒ¬ãƒ¼ãƒ‘ãƒ¼ã‚’æ§‹ç¯‰ã™ã‚‹æ–¹æ³•"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Python Scrapy 5éƒ¨æ§‹æˆã®åˆå¿ƒè€…å‘ã‘ã‚·ãƒªãƒ¼ã‚º\n",
    "- Part 1: Basic Scrapy Spider\n",
    "  - Scrapyã®åŸºæœ¬ã‚’ç¢ºèªã—ã€æœ€åˆã®Scrapyã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚\n",
    "- Part 2ï¼šæ±šã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã¨ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã®å‡¦ç†\n",
    "  - Webãƒ‡ãƒ¼ã‚¿ã¯å„ä»‹ã§æ§‹é€ åŒ–ã•ã‚Œã¦ãŠã‚‰ãšã€å¤šãã®ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã‚’æŒã¤ã“ã¨ãŒã§ãã¾ã™ã€‚\n",
    "  - Itemsã€Itemloadersã€Item Pipelineã‚’ä½¿ç”¨ã—ã¦ã€ã“ã‚Œã‚‰ã®ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã«å¯¾ã—ã¦ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ã‚’å …ç‰¢ã«ã—ã¾ã™ã€‚\n",
    "- Part 3ï¼šãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜\n",
    "  - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã€CSVãƒ•ã‚¡ã‚¤ãƒ«ã€JSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€S3ãƒã‚±ãƒƒãƒˆã‹ã‚‰ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã™ã‚‹æ–¹æ³•ã¯ã•ã¾ã–ã¾ã§ã™ã€‚\n",
    "  - ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã™ã‚‹ã•ã¾ã–ã¾ãªæ–¹æ³•ã‚’æ¤œè¨ã—ã€ãã®é•·æ‰€ã€çŸ­æ‰€ã€ã©ã®ã‚ˆã†ãªå ´é¢ã§ä½¿ã†ã‹ã«ã¤ã„ã¦èª¬æ˜ã—ã¾ã™ã€‚\n",
    "- Part4ï¼šãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ãƒ—ãƒ­ã‚­ã‚·\n",
    "  - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨IPã‚’ç®¡ç†ã—ã€ãƒ–ãƒ­ãƒƒã‚¯ã•ã‚Œãªã„ã‚ˆã†ã«ã™ã‚‹ã“ã¨ã§ã€ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ã‚’æœ¬ç•ªç’°å¢ƒã«å¯¾å¿œã•ã›ã¾ã™ã€‚\n",
    "- Part 5: ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã€ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã€ã‚¸ãƒ§ãƒ–ã®å®Ÿè¡Œ\n",
    "  - ã‚µãƒ¼ãƒãƒ¼ä¸Šã«ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã€[ScrapeOps](https://scrapeops.io/)ã‚’ä»‹ã—ã¦ã‚¸ãƒ§ãƒ–ã®ç›£è¦–ã¨ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã‚’è¡Œã†ã€‚"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CSSã‚»ãƒ¬ã‚¯ã‚¿ã¨XPathè¡¨ç¾ã®è§£æ\n",
    "- ãƒ‡ãƒ¼ã‚¿å½¢å¼ï¼ˆCSVã€JSONã€XMLï¼‰ãŠã‚ˆã³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ï¼ˆFTPã€S3ã€ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ï¼‰\n",
    "- å …ç‰¢ãªã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚µãƒãƒ¼ãƒˆ\n",
    "- åŒæ™‚å®Ÿè¡Œç®¡ç†\n",
    "- è‡ªå‹•å†è©¦è¡Œ\n",
    "- ã‚¯ãƒƒã‚­ãƒ¼ã¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®å‡¦ç†\n",
    "- ã‚¯ãƒ­ãƒ¼ãƒ«ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ã¨å†…è”µã®ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚µãƒãƒ¼ãƒˆ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beginners Scrapy Tutorial"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Setup your Python Environment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Scrapy Is Installed\n",
    "\n",
    "```bash\n",
    "(venv) c01 (ğŸ˜ :main *) :$ scrapy\n",
    "\n",
    "Scrapy 2.9.0 - no active project\n",
    "\n",
    "Usage:\n",
    "  scrapy <command> [options] [args]\n",
    "\n",
    "Available commands:\n",
    "  bench         Run quick benchmark test\n",
    "  fetch         Fetch a URL using the Scrapy downloader\n",
    "  genspider     Generate new spider using pre-defined templates\n",
    "  runspider     Run a self-contained spider (without creating a project)\n",
    "  settings      Get settings values\n",
    "  shell         Interactive scraping console\n",
    "  startproject  Create new project\n",
    "  version       Print Scrapy version\n",
    "  view          Open URL in browser, as seen by Scrapy\n",
    "\n",
    "  [ more ]      More commands available when run from project directory\n",
    "\n",
    "Use \"scrapy <command> -h\" to see more info about a command\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Setup Our Scrapy Project\n",
    "\n",
    "```bash\n",
    "# scrapyãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ä½œæˆ\n",
    "(venv) c01 (ğŸ˜ :main *) :$ scrapy startproject chocolatescraper\n",
    "\n",
    "New Scrapy project 'chocolatescraper', using template directory '/Users/takeru/@LEARNING/Python/python-scrapy-playbook-scrapyops/venv/lib/python3.10/site-packages/scrapy/templates/project', created in:\n",
    "    /Users/takeru/@LEARNING/Python/python-scrapy-playbook-scrapyops/c01/chocolatescraper\n",
    "\n",
    "You can start your first spider with:\n",
    "    cd chocolatescraper\n",
    "    scrapy genspider example example.com\n",
    "```\n",
    "\n",
    "```bash\n",
    "# chocolatescraperãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç§»å‹•\n",
    "cd chocolatescraper\n",
    "```\n",
    "\n",
    "```bash\n",
    "# chocolatescraperãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®tree\n",
    "(venv) chocolatescraper (ğŸ˜ :main *) :$ tree\n",
    "\n",
    ".\n",
    "â”œâ”€â”€ chocolatescraper\n",
    "â”‚   â”œâ”€â”€ __init__.py\n",
    "â”‚   â”œâ”€â”€ items.py\n",
    "â”‚   â”œâ”€â”€ middlewares.py\n",
    "â”‚   â”œâ”€â”€ pipelines.py\n",
    "â”‚   â”œâ”€â”€ settings.py\n",
    "â”‚   â””â”€â”€ spiders\n",
    "â”‚       â””â”€â”€ __init__.py\n",
    "â””â”€â”€ scrapy.cfg\n",
    "\n",
    "3 directories, 7 files\n",
    "```\n",
    "\n",
    "- `settings.py`\n",
    "  - ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚„ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢ã®æœ‰åŠ¹åŒ–ãªã©ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã™ã¹ã¦ã®è¨­å®šãŒå«ã¾ã‚Œã‚‹å ´æ‰€ã§ã™ã€‚\n",
    "  - é…å»¶ã€åŒæ™‚å®Ÿè¡Œã€ãã®ä»–å¤šãã®ã“ã¨ã‚’å¤‰æ›´ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚\n",
    "- `items.py`\n",
    "  - æŠ½å‡ºã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚\n",
    "  - Scrapy Itemã‚¯ãƒ©ã‚¹ã‚’ç¶™æ‰¿ã—ã€ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«ï¼ˆProductItemã®ã‚ˆã†ãªï¼‰ã‚’å®šç¾©ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™\n",
    "- `pipelines.py`\n",
    "  - ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ãŒç”Ÿæˆã—ãŸã‚¢ã‚¤ãƒ†ãƒ ãŒæ¸¡ã•ã‚Œã‚‹å ´æ‰€ã§ã€ä¸»ã«ãƒ†ã‚­ã‚¹ãƒˆã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã‚„ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›ã‚„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼ˆCSVã€JSON SQLãªã©ï¼‰ã¸ã®æ¥ç¶šã«ä½¿ç”¨ã—ã¾ã™ã€‚\n",
    "- `middlewares.py`\n",
    "  - ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒè¡Œã‚ã‚Œã€scrapy ãŒãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å‡¦ç†ã™ã‚‹æ–¹æ³•ã‚’å¤‰æ›´ã—ãŸã„ã¨ãã«ä¾¿åˆ©ã§ã™ã€‚\n",
    "- `scrapy.cfg`\n",
    "  - ã„ãã¤ã‹ã®ãƒ‡ãƒ—ãƒ­ã‚¤è¨­å®šãªã©ã‚’å¤‰æ›´ã™ã‚‹ãŸã‚ã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã§ã™ã€‚"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3- Creating Our Spider\n",
    "\n",
    "- Spider\n",
    "  - `start_url` ã®ãƒªã‚¹ãƒˆã‚’å—ã‘å–ã‚Šã€ãã‚Œãã‚Œã‚’ `parse` ãƒ¡ã‚½ãƒƒãƒ‰ã§ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã™ã‚‹ã€‚\n",
    "- CrawlSpider \n",
    "  - è¦‹ã¤ã‘ãŸãƒªãƒ³ã‚¯ã‚’ãŸã©ã£ã¦ã€ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆå…¨ä½“ã‚’ã‚¯ãƒ­ãƒ¼ãƒ«ã™ã‚‹ã‚ˆã†ã«è¨­è¨ˆã•ã‚Œã¦ã„ã‚‹ã€‚\n",
    "- SitemapSpider\n",
    "  - ã‚µã‚¤ãƒˆãƒãƒƒãƒ—ã‹ã‚‰ URL ã‚’æŠ½å‡ºã™ã‚‹ã‚ˆã†ã«è¨­è¨ˆã•ã‚Œã¦ã‚‹ã€‚\n",
    "\n",
    "```bash\n",
    "# æ–°ã—ã„æ±ç”¨ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ã‚’ä½œæˆã™ã‚‹ã«ã¯ã€`genspider`ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã™ã‚‹ã ã‘ã§ã™ï¼š\n",
    "# scrapy genspider <name_of_spider> <website>\n",
    "(venv) chocolatescraper (ğŸ˜ :main *) :$ scrapy genspider chocolatespider chocolate.co.uk\n",
    "\n",
    "Created spider 'chocolatespider' using template 'basic' in module:\n",
    "  chocolatescraper.spiders.chocolatespider\n",
    "```\n",
    "\n",
    "ã“ã‚Œã§ `spiders` ãƒ•ã‚©ãƒ«ãƒ€ã«æ–°ã—ã„ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ãŒè¿½åŠ ã•ã‚Œã€æ¬¡ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ï¼š\n",
    "\n",
    "```python\n",
    "# chocolatespider.py\n",
    "\n",
    "import scrapy\n",
    "\n",
    "class ChocolatespiderSpider(scrapy.Spider):\n",
    "    name = 'chocolatespider'\n",
    "    allowed_domains = ['chocolate.co.uk']\n",
    "    start_urls = ['http://chocolate.co.uk/']\n",
    "\n",
    "    def parse(self, response):\n",
    "        pass\n",
    "```\n",
    "\n",
    "ã“ã“ã§ã¯ã€`genspider`ã‚³ãƒãƒ³ãƒ‰ãŒã€`Spider`ã‚¯ãƒ©ã‚¹ã¨ã„ã†å½¢ã§ã€ç§ãŸã¡ãŒä½¿ç”¨ã™ã‚‹ãŸã‚ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ã‚’ä½œæˆã—ãŸã“ã¨ã‚’ç¢ºèªã—ã¾ã™ã€‚\n",
    "\n",
    "ã“ã®ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ãƒ»ã‚¯ãƒ©ã‚¹ã«ã¯ä»¥ä¸‹ã®ã‚‚ã®ãŒã‚ã‚Šã¾ã™ï¼š\n",
    "\n",
    "- name\n",
    "  - ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ã«åå‰ã‚’ã¤ã‘ã‚‹ã‚¯ãƒ©ã‚¹å±æ€§ã§ã™ã€‚\n",
    "  - ã‚ã¨ã§ `scrapy crawl <spider_name>` ã¨ã—ã¦ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ã‚’å®Ÿè¡Œã™ã‚‹ã¨ãã«ã€ã“ã®åå‰ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚\n",
    "- allowed_domains\n",
    "  - ã‚¯ãƒ©ã‚¹å±æ€§ã§ã€Scrapyã« `chocolate.co.uk` ãƒ‰ãƒ¡ã‚¤ãƒ³ã®ãƒšãƒ¼ã‚¸ã®ã¿ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã™ã‚‹ã‚ˆã†ã«æŒ‡ç¤ºã—ã¾ã™ã€‚\n",
    "  - ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼ãŒæš´èµ°ã—ã¦å¤šãã®ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã™ã‚‹ã®ã‚’é˜²ããŸã‚ã§ã™ã€‚\n",
    "  - ã“ã‚Œã¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ã™ã€‚\n",
    "- start_urls\n",
    "  - Scrapyã«ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã™ã¹ãæœ€åˆã®URLã‚’æŒ‡ç¤ºã™ã‚‹ã‚¯ãƒ©ã‚¹å±æ€§ã§ã™ã€‚\n",
    "  - ã“ã‚Œã¯å°‘ã—ã¥ã¤å¤‰æ›´ã—ã¦ã„ãã¾ã™ã€‚\n",
    "- parse\n",
    "  - ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆã‹ã‚‰ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å—ä¿¡ã—ãŸå¾Œã€`parse`é–¢æ•°ãŒå‘¼ã³å‡ºã•ã‚Œã¾ã™ã€‚\n",
    "\n",
    "ã“ã®Spiderã‚’ä½¿ã„å§‹ã‚ã‚‹ã«ã¯ã€2ã¤ã®ã“ã¨ã‚’ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼š\n",
    "\n",
    "- start_urls`ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã—ãŸã„URL <https://www.chocolate.co.uk/collections/all>ã«å¤‰æ›´ã™ã‚‹ã€‚\n",
    "- ãƒ‘ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’ `parse` é–¢æ•°ã«æŒ¿å…¥ã™ã‚‹ã€‚"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Update Start Urls\n",
    "\n",
    "```python\n",
    "# chocolatespider.py\n",
    "\n",
    "import scrapy\n",
    "\n",
    "class ChocolatespiderSpider(scrapy.Spider):\n",
    "    name = 'chocolatespider'\n",
    "    allowed_domains = ['chocolate.co.uk']\n",
    "    start_urls = ['https://chocolate.co.uk/collections/all']\n",
    "\n",
    "    def parse(self, response):\n",
    "        pass\n",
    "```\n",
    "\n",
    "æ¬¡ã«ã€ãƒšãƒ¼ã‚¸ã‹ã‚‰å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ã‚’è§£æã™ã‚‹ãŸã‚ã®CSSã‚»ãƒ¬ã‚¯ã‚¿ã‚’ä½œæˆã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n",
    "\n",
    "ã“ã‚Œã‚’è¡Œã†ã«ã¯ã€Scrapy Shellã‚’ä½¿ç”¨ã—ã¾ã™ã€‚"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 - Scrapy Shell: Finding Our CSS Selectors\n",
    "\n",
    "HTMLãƒšãƒ¼ã‚¸ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã™ã‚‹ã«ã¯ã€[XPath](https://www.w3schools.com/xml/xpath_intro.asp)ã¾ãŸã¯[CSSã‚»ãƒ¬ã‚¯ã‚¿](https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Selectors)ã‚’ä½¿ç”¨ã—ã¦ã€Scrapyã«ãƒšãƒ¼ã‚¸ã®ã©ã“ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã®ã‹ã‚’ä¼ãˆã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚XPathã¨CSSã‚»ãƒ¬ã‚¯ã‚¿ã¯ã€ScrapyãŒDOMãƒ„ãƒªãƒ¼ã‚’ãƒŠãƒ“ã‚²ãƒ¼ãƒˆã—ã€å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ã®å ´æ‰€ã‚’è¦‹ã¤ã‘ã‚‹ãŸã‚ã®å°ã•ãªãƒãƒƒãƒ—ã®ã‚ˆã†ãªã‚‚ã®ã§ã™ã€‚ã“ã®ã‚¬ã‚¤ãƒ‰ã§ã¯ã€ãƒšãƒ¼ã‚¸ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’è§£æã™ã‚‹ãŸã‚ã«CSSã‚»ãƒ¬ã‚¯ã‚¿ã‚’ä½¿ç”¨ã™ã‚‹ã¤ã‚‚ã‚Šã§ã™ã€‚ãã—ã¦ã€ã“ã‚Œã‚‰ã®CSSã‚»ãƒ¬ã‚¯ã‚¿ã‚’ä½œæˆã™ã‚‹ãŸã‚ã«ã€ç§ãŸã¡ã¯[Scrapy Shell](https://docs.scrapy.org/en/latest/topics/shell.html)ã‚’ä½¿ç”¨ã™ã‚‹äºˆå®šã§ã™ã€‚\n",
    "\n",
    "Scrapyã®ç´ æ™´ã‚‰ã—ã„æ©Ÿèƒ½ã®1ã¤ã¯ã€ã‚ãªãŸãŒã™ãã«ã‚ãªãŸã®XPathã¨CSSã‚»ãƒ¬ã‚¯ã‚¿ã‚’ãƒ†ã‚¹ãƒˆã—ã€ãƒ‡ãƒãƒƒã‚°ã™ã‚‹ã“ã¨ãŒã§ãã€çµ„ã¿è¾¼ã¿ã®ã‚·ã‚§ãƒ«ãŒä»˜å±ã—ã¦ã„ã‚‹ã“ã¨ã§ã™ã€‚XPathã‚„CSSã®ã‚»ãƒ¬ã‚¯ã‚¿ãŒæ­£ã—ã„ã‹ã©ã†ã‹ã‚’ç¢ºèªã™ã‚‹ãŸã‚ã«ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã‚’å®Ÿè¡Œã™ã‚‹ä»£ã‚ã‚Šã«ã€ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã«ç›´æ¥å…¥åŠ›ã—ã¦çµæœã‚’ç¢ºèªã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚\n",
    "\n",
    "```bash\n",
    "# Scrapyã‚·ã‚§ãƒ«ã‚’é–‹ãã«ã¯ã€æ¬¡ã®ã‚³ãƒãƒ³ãƒ‰ã‚’ä½¿ç”¨ã—ã¾ã™ï¼š\n",
    "(venv) chocolatescraper (ğŸ˜ :main *) :$ scrapy shell\n",
    "\n",
    "2023-05-29 20:06:24 [scrapy.utils.log] INFO: Scrapy 2.9.0 started (bot: chocolatescraper)\n",
    "2023-05-29 20:06:24 [scrapy.utils.log] INFO: Versions: lxml 4.9.2.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.1, Twisted 22.10.0, Python 3.10.11 (main, Apr 24 2023, 17:34:58) [Clang 14.0.3 (clang-1403.0.22.14.1)], pyOpenSSL 23.1.1 (OpenSSL 3.1.0 14 Mar 2023), cryptography 40.0.2, Platform macOS-13.3.1-x86_64-i386-64bit\n",
    "2023-05-29 20:06:24 [scrapy.crawler] INFO: Overridden settings:\n",
    "{'BOT_NAME': 'chocolatescraper',\n",
    " 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',\n",
    " 'FEED_EXPORT_ENCODING': 'utf-8',\n",
    " 'LOGSTATS_INTERVAL': 0,\n",
    " 'NEWSPIDER_MODULE': 'chocolatescraper.spiders',\n",
    " 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',\n",
    " 'ROBOTSTXT_OBEY': True,\n",
    " 'SPIDER_MODULES': ['chocolatescraper.spiders'],\n",
    " 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}\n",
    "2023-05-29 20:06:24 [asyncio] DEBUG: Using selector: KqueueSelector\n",
    "2023-05-29 20:06:24 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor\n",
    "2023-05-29 20:06:24 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop\n",
    "2023-05-29 20:06:24 [scrapy.extensions.telnet] INFO: Telnet Password: f3038c0cc138d466\n",
    "2023-05-29 20:06:24 [scrapy.middleware] INFO: Enabled extensions:\n",
    "['scrapy.extensions.corestats.CoreStats',\n",
    " 'scrapy.extensions.telnet.TelnetConsole',\n",
    " 'scrapy.extensions.memusage.MemoryUsage']\n",
    "2023-05-29 20:06:24 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
    "['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\n",
    " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
    " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
    " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
    " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
    " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
    " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
    " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
    " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
    " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
    " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
    " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
    "2023-05-29 20:06:24 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
    "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
    " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
    " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
    " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
    " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
    "2023-05-29 20:06:24 [scrapy.middleware] INFO: Enabled item pipelines:\n",
    "[]\n",
    "2023-05-29 20:06:24 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
    "2023-05-29 20:06:24 [asyncio] DEBUG: Using selector: KqueueSelector\n",
    "[s] Available Scrapy objects:\n",
    "[s]   scrapy     scrapy module (contains scrapy.Request, scrapy.Selector, etc)\n",
    "[s]   crawler    <scrapy.crawler.Crawler object at 0x10dcf76a0>\n",
    "[s]   item       {}\n",
    "[s]   settings   <scrapy.settings.Settings object at 0x10dcf6ce0>\n",
    "[s] Useful shortcuts:\n",
    "[s]   fetch(url[, redirect=True]) Fetch URL and update local objects (by default, redirects are followed)\n",
    "[s]   fetch(req)                  Fetch a scrapy.Request and update local objects \n",
    "[s]   shelp()           Shell help (print this help)\n",
    "[s]   view(response)    View response in a browser\n",
    "2023-05-29 20:06:25 [asyncio] DEBUG: Using selector: KqueueSelector\n",
    "In [1]: \n",
    "```\n",
    "\n",
    "```bash\n",
    "# scrapy shellã‚’æŠœã‘ã‚‹\n",
    "In [1]: quit\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetch The Page\n",
    "\n",
    "CSSã‚»ãƒ¬ã‚¯ã‚¿ã‚’ä½œæˆã™ã‚‹ãŸã‚ã«ã€æ¬¡ã®ãƒšãƒ¼ã‚¸ã§ãƒ†ã‚¹ãƒˆã—ã¾ã™ï¼š\n",
    "\n",
    "<https://www.chocolate.co.uk/collections/all>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
