{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Intro to Web Scraping With Scrapy](https://scrapeops.io/python-scrapy-playbook/scrapy-web-scraping-intro/)\n",
    "\n",
    "# Scrapy を使った Web スクレイピングの紹介"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Scrapyとは何か？"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapyとほかのスクレイピングライブラリやフレームワークとの違いについて\n",
    "\n",
    "- GET、POSTなどのリクエストの作成\n",
    "- CSSとXPathセレクタを使ったページからのデータ抽出\n",
    "- 失敗したリクエストを検出し、自動的に再試行する\n",
    "- 組み込みの同時実行機能によるリクエストの並列化\n",
    "- ページネーション、サイトマップ、リンクフォローによるWebサイト全体のクローリング\n",
    "- パイプラインによるスクレイピングデータのクリーニング、検証、後処理\n",
    "- CSV/JSONファイル、データベース、オブジェクトストレージへのデータ保存\n",
    "\n",
    "その他にも様々な機能があります。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapy をいつ使用する必要がありますか\n",
    "\n",
    "- 1 大規模なウェブスクレイピング\n",
    "- 2 強力なウェブスクレイピングフレームワークを学びたい\n",
    "- 3 Webスクレイピングを始めたばかりで、小さなプロジェクトを持っている\n",
    "- 4 Javascriptが重いWebサイトのスクレイピング"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapyの概要"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 The Scrapy Project\n",
    "\n",
    "```bash\n",
    "scrapy startproject <project_name>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
